{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinzhiT/5750-project-2/blob/main/project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 2"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Clustering Gaussian Blobs using $k$-means"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate 5 Gaussian blobs in 10 dimensions\n",
        "X, y_true = make_blobs(\n",
        "    n_samples=1000,\n",
        "    centers=5,\n",
        "    n_features=10,\n",
        "    cluster_std=1.5,\n",
        "    random_state=1)        # reproducibility\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "print(type(X),X.shape)\n",
        "print(type(y_true),y_true.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB136H0PGKq1",
        "outputId": "6fcea671-2dcb-4b43-c98a-83ec001de164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (1000, 10)\n",
            "<class 'numpy.ndarray'> (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "\n",
        "X, y_true = make_blobs(n_samples=1000, centers=5, n_features=10,\n",
        "                       cluster_std=1.5, random_state=1)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "k = 5\n",
        "kmeans = KMeans(n_clusters=k, n_init=20, random_state=1).fit(X)\n",
        "labels_pred = kmeans.labels_\n",
        "print(\"Smallest inertia (k=5):\", round(kmeans.inertia_, 3))  # ~924.316\n",
        "\n",
        "cm_raw = confusion_matrix(y_true, labels_pred, labels=np.arange(k))\n",
        "row_ind, col_ind = linear_sum_assignment(-cm_raw)     # maximize correct\n",
        "mapping = {pred: true for true, pred in zip(row_ind, col_ind)}\n",
        "labels_matched = np.vectorize(lambda c: mapping[c])(labels_pred)\n",
        "cm_matched = confusion_matrix(y_true, labels_matched, labels=np.arange(k))\n",
        "print(\"Matched accuracy:\", np.trace(cm_matched) / np.sum(cm_matched))\n",
        "\n",
        "pca = PCA(n_components=2, random_state=1).fit(X)\n",
        "X_2d = pca.transform(X)\n",
        "centers_2d = pca.transform(kmeans.cluster_centers_)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.scatter(X_2d[:,0], X_2d[:,1], c=labels_pred, s=10)\n",
        "plt.scatter(centers_2d[:,0], centers_2d[:,1], marker=\"X\", s=200,\n",
        "            linewidths=1, edgecolors=\"black\")\n",
        "plt.title(\"K-means (k=5) on Gaussian Blobs â€” PCA 2D view\")\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
        "plt.tight_layout(); plt.savefig(\"pca_clusters_centers.png\", dpi=200); plt.close()\n",
        "\n",
        "k_values = list(range(1, 8))\n",
        "inertias = []\n",
        "for kk in k_values:\n",
        "    km = KMeans(n_clusters=kk, n_init=3, random_state=1).fit(X)\n",
        "    inertias.append(km.inertia_)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(k_values, inertias, marker=\"o\")\n",
        "plt.title(\"Elbow Analysis (k vs. inertia)\")\n",
        "plt.xlabel(\"k\"); plt.ylabel(\"Inertia\")\n",
        "plt.xticks(k_values)\n",
        "plt.tight_layout(); plt.savefig(\"elbow_plot.png\", dpi=200); plt.close()\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(cm_matched, aspect=\"auto\"); plt.colorbar()\n",
        "plt.title(\"Confusion Matrix (true vs. matched predicted labels)\")\n",
        "plt.xlabel(\"Predicted (matched)\"); plt.ylabel(\"True\")\n",
        "plt.xticks(ticks=np.arange(k), labels=[str(i) for i in range(k)])\n",
        "plt.yticks(ticks=np.arange(k), labels=[str(i) for i in range(k)])\n",
        "plt.tight_layout(); plt.savefig(\"confusion_matrix_matched.png\", dpi=200); plt.close()\n"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM",
        "outputId": "e03fd203-e29b-4248-e5a4-553181849691",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smallest inertia (k=5): 924.316\n",
            "Matched accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Clustering Fashion-MNIST using $k$-means"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST from OpenML\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "X, y = fetch_openml(\"Fashion-MNIST\", version=1, as_frame=False, parser=\"auto\", return_X_y=True)\n",
        "y = y.astype(int)\n",
        "\n",
        "print(type(X),X.shape)\n",
        "print(type(y),y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9IQwhgcIVOl",
        "outputId": "5cc76846-93c1-492c-a1ab-6388f8300da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (70000, 784)\n",
            "<class 'numpy.ndarray'> (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "0REsDBunNmEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Dimensionality reduction for Fashion-MNIST"
      ],
      "metadata": {
        "id": "6Bpow7TrZ7iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "ejYYENCQZ9tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Clustering Fashion-MNIST using spectral clustering"
      ],
      "metadata": {
        "id": "fOTFcjWOfCZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "MRB_nw21fI24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}